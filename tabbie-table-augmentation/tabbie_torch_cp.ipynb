{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spectacular-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "from overrides import overrides\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scripts.to_npy import ToNpy\n",
    "\n",
    "from allennlp.nn import util\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules import FeedForward, TextFieldEmbedder, Seq2VecEncoder\n",
    "from allennlp.nn import InitializerApplicator, RegularizerApplicator\n",
    "from allennlp.training.metrics.categorical_accuracy import CategoricalAccuracy\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "\n",
    "from table_embedder.models.lib.bert_token_embedder import PretrainedBertEmbedder\n",
    "\n",
    "from table_embedder.models.embedder_util import TableUtil\n",
    "# from embedder_util import TableUtil\n",
    "# from embedder_util import PredUtil\n",
    "from table_embedder.models.lib.stacked_self_attention import StackedSelfAttentionEncoder\n",
    "# from lib.stacked_self_attention import StackedSelfAttentionEncoder\n",
    "from allennlp.models.archival import load_archive\n",
    "\n",
    "from table_embedder.models.cache_util import CacheUtil\n",
    "\n",
    "from torch import nn\n",
    "from torch import tensor\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d95bd9e-5b25-4484-9aef-8b0e3a11f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1eac748-dfee-483a-a27b-cc58089e12e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PretrainedBertEmbedder(pretrained_model='bert-base-uncased', top_layer_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88261272-d5be-4873-b356-a85bcf7826fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = [{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "               , 'num_rows': 3\n",
    "               , 'num_cols': 5\n",
    "               , 'header': ['size', 'us', 'inches', 'china', 'japan (cm)']\n",
    "               , 'cell_labels': None\n",
    "               , 'col_labels': None\n",
    "               , 'table_labels': None\n",
    "                , 'table_data_raw': [['6/7', 'xs', '9.125', '235','23']\n",
    "                                     , ['s', '7/8', '40-41', '245','24']\n",
    "                                     , ['m', '8/9', '9.875', '255','25']]\n",
    "                , 'table': [['size', 'us', 'inches', 'china', 'japan (cm)']\n",
    "                            , ['6/7', 'xs', '9.125', '235','23']\n",
    "                            , ['s', '7/8', '40-41', '245','24']\n",
    "                            , ['m', '8/9', '9.875', '255','25']]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf295b8-99d6-4574-8029-8b8a4bab821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_headers = {'bert': {'token_ids': tensor([[[ 101, 2946,  102,    0,    0,    0],\n",
    "         [ 101, 2149,  102,    0,    0,    0],\n",
    "         [ 101, 5282,  102,    0,    0,    0],\n",
    "         [ 101, 2859,  102,    0,    0,    0],\n",
    "        [ 101, 2900, 1006, 4642, 1007,  102]]], device='cuda:0')\n",
    ", 'mask': tensor([[[ True,  True,  True, False, False, False],\n",
    "         [ True,  True,  True, False, False, False],\n",
    "         [ True,  True,  True, False, False, False],\n",
    "         [ True,  True,  True, False, False, False],\n",
    "        [ True,  True,  True,  True,  True,  True]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0cdee08-c45c-44cd-9dea-53ed6d72be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_cells = {'bert': {'token_ids': tensor([[[[  101,  1020,  1013,  1021,   102],\n",
    "          [  101,  1060,  2015,   102,     0],\n",
    "          [  101,  1023,  1012,  8732,   102],\n",
    "          [  101, 17825,   102,     0,   0],[101,  2603,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1055,   102,     0,     0],\n",
    "          [  101,  1021,  1013,  1022,   102],\n",
    "          [  101,  2871,  1011,  4601,   102],\n",
    "          [  101, 21005,   102,     0,     0],\n",
    "           [101,  2484,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1049,   102,     0,     0],\n",
    "          [  101,  1022,  1013,  1023,   102],\n",
    "          [  101,  1023,  1012, 27658,   102],\n",
    "          [  101, 20637,   102,     0,     0],\n",
    "          [ 101,  2423,   102,     0,     0]]]], device='cuda:0')\n",
    ", 'mask': tensor([[[[ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "        [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "         [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False]]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409389d4-e262-4a2e-b8eb-ad006a33bccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7234fa7-7e1d-4a45-b728-0ce261764342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, dict, dict)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(table_info), type(indexed_headers), type(indexed_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19559348-2ea8-4082-ac7f-c054fb0f1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TableEmbedderTorch().to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acbaba10-87a9-41ad-8dfc-22c6c9fb8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, prob = model(table_info,indexed_headers, indexed_cells, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee6dc0fa-2481-4aaa-8d5b-7e1cdd1e773d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127656])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e976560-0b05-4346-b163-14cc981d0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableEmbedderTorch(nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(TableEmbedderTorch,self).__init__()\n",
    "\n",
    "        self.num_max_row_pos = 31  # FIXME: why different than the row_pos_embedding in cp.jsonnet? -- Corrected it to be 31 as per the jsonnet. The model is saved accordingly\n",
    "        self.num_max_col_pos = 25\n",
    "        self.n_classes = 127656  # FIXME: we'll update this, since I can't reproduce\n",
    "#        self.n_seed_cols = int(os.getenv('n_seed_cols'))\n",
    "        ## As per the paper n_seed_cols = 1/2/3\n",
    "        self.n_seed_cols = 5\n",
    "        \"\"\"\n",
    "        from exp/col_pop/cp.jsonnet\n",
    "        \"row_pos_embedding\": {\n",
    "            \"num_embeddings\": 31,\n",
    "            \"embedding_dim\": 768\n",
    "        },\n",
    "        \"col_pos_embedding\": {\n",
    "            \"num_embeddings\": 25,\n",
    "            \"embedding_dim\": 768\n",
    "        },\n",
    "        \"\"\"\n",
    "        self.row_pos_embedding = Embedding(num_embeddings=self.num_max_row_pos, embedding_dim=768)\n",
    "        self.col_pos_embedding = Embedding(num_embeddings=self.num_max_col_pos, embedding_dim=768)\n",
    "\n",
    "        \"\"\"\n",
    "        \"top_feedforward\": {\n",
    "          \"input_dim\": 768*3,\n",
    "          # \"input_dim\": 768,\n",
    "          \"num_layers\": 1,\n",
    "          \"hidden_dims\": [127656],\n",
    "          \"activations\": [\"linear\"],\n",
    "          \"dropout\": [0.0]\n",
    "        }\n",
    "        \"\"\"\n",
    "        # FIXME: replace with normal torch.nn.Linear\n",
    "        # NOTE: this is the only parameter not initialized from the pretrained TABBIE model\n",
    "        # NOTE : Activation used in linear i.e. basically as per allennlp module it is ignored - https://github.com/allenai/allennlp/blob/master/allennlp/nn/activations.py#L78\n",
    "        \n",
    "        self.top_feedforward = nn.Linear(768*self.n_seed_cols, self.n_classes)\n",
    "        self.Dropout = nn.Dropout(p = 0.0)\n",
    "#        self.top_feedforward = FeedForward(768*3, 1, [self.n_classes], Activation.by_name(\"linear\"), [0.0])\n",
    "\n",
    "        \"\"\"\n",
    "        \"bert_embbeder\": {\n",
    "            \"pretrained_model\": \"bert-base-uncased\",\n",
    "            \"top_layer_only\": true,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.bert_embedder = PretrainedBertEmbedder(pretrained_model='bert-base-uncased', top_layer_only=True)\n",
    "\n",
    "        \"\"\"\n",
    "        from exp/col_pop/cp.jsonnet\n",
    "        \"transformer_row1\": {\n",
    "              \"input_dim\": 768,\n",
    "              \"hidden_dim\": 768,\n",
    "              \"projection_dim\": 768,\n",
    "              \"feedforward_hidden_dim\": 3072,\n",
    "              # \"dropout_prob\": 0.0,\n",
    "              # \"residual_dropout_prob\": 0.0,\n",
    "              # \"attention_dropout_prob\": 0.0,\n",
    "              \"num_layers\": 1,\n",
    "              \"num_attention_heads\": 12,\n",
    "              \"use_positional_encoding\": false,\n",
    "            }\n",
    "        \"\"\"\n",
    "        self.transformer_col1 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col2 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col3 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col4 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col5 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col6 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col7 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col8 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col9 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col10 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col11 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col12 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "\n",
    "        self.transformer_row1 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row2 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row3 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row4 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row5 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row6 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row7 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row8 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row9 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row10 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row11 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row12 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # FIXME: we'll try loss both ways\n",
    "        self.loss = torch.nn.BCELoss()\n",
    "        # self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # FIXME: unused, torch.load_state_dict with strict false\n",
    "        # self.compose_ff = compose_ff\n",
    "        # self.feedforward = feedforward\n",
    "\n",
    "        self.cache_usage = os.getenv(\"cache_usage\")\n",
    "        # FIXME: maybe don't pull so much from env variables\n",
    "        # TODO: try these as plain parameters, initialized from the saved clscol and clsrow embeddings\n",
    "        self.cls_col = np.load('/work/arnaik_umass_edu/tabbie/data/clscol.npy')\n",
    "        self.cls_row = np.load('/work/arnaik_umass_edu/tabbie/data/clsrow.npy')\n",
    "\n",
    "        self.opt_level = 'O0'\n",
    "\n",
    "        if self.cache_usage is not None:\n",
    "            self.cache_util = CacheUtil(self.cache_usage, os.getenv(\"cell_db_path\"))\n",
    "        else:\n",
    "            self.cache_util = None\n",
    "            \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        model_parameters = dict(self.named_parameters())\n",
    "        archived_parameters = torch.load('/work/arnaik_umass_edu/model_named.pt') # Archieved weights of feedforward layers discarded.\n",
    "        for name, weights in archived_parameters.items():\n",
    "            if name in model_parameters:\n",
    "                new_weights = weights.data\n",
    "                model_parameters[name].data.copy_(new_weights)\n",
    "\n",
    "    def get_tabemb(self, bert_header, bert_data, n_rows, n_cols, bs, table_mask, nrows, ncols):\n",
    "        row_pos_ids = torch.arange(0, self.num_max_row_pos, device=self.device, dtype=torch.long)\n",
    "        col_pos_ids = torch.arange(0, self.num_max_col_pos, device=self.device, dtype=torch.long)\n",
    "\n",
    "        n_rows += 1  # row CLS\n",
    "        n_cols += 1  # col CLS\n",
    "        # NOTE: there is no need for a copy, but it doesn't really matter\n",
    "        cls_col = torch.from_numpy(copy.deepcopy(self.cls_col)).to(device=self.device)\n",
    "        cls_row = torch.from_numpy(copy.deepcopy(self.cls_row)).to(device=self.device)\n",
    "        row_pos_embs = self.row_pos_embedding(row_pos_ids[:n_rows + 1])\n",
    "        col_pos_embs = self.col_pos_embedding(col_pos_ids[:n_cols])\n",
    "\n",
    "        for i in range(1, 13):\n",
    "            transformer_row = getattr(self, 'transformer_row{}'.format(str(i)))\n",
    "            transformer_col = getattr(self, 'transformer_col{}'.format(str(i)))\n",
    "            if i == 1:\n",
    "                bert_data = TableUtil.add_cls_tokens(bert_header, bert_data, cls_row, cls_col, bs, n_rows, n_cols)\n",
    "                bert_data += row_pos_embs.expand((bs, n_cols, n_rows + 1, 768)).permute(0, 2, 1, 3).expand_as(bert_data)\n",
    "                bert_data += col_pos_embs.expand((bs, n_rows + 1, n_cols, 768)).expand_as(bert_data)\n",
    "                # table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\n",
    "                table_mask = TableUtil.add_cls_mask(table_mask, bs, n_rows, n_cols, self.device, nrows, ncols)\n",
    "                col_embs = TableUtil.get_col_embs(bert_data, bs, n_rows, n_cols, table_mask, transformer_col,\n",
    "                                                  self.opt_level)\n",
    "                row_embs = TableUtil.get_row_embs(bert_data, bs, n_rows, n_cols, table_mask, transformer_row,\n",
    "                                                  self.opt_level)\n",
    "            else:\n",
    "                row_embs = TableUtil.get_row_embs(ave_embs, bs, n_rows, n_cols, table_mask, transformer_row,\n",
    "                                                  self.opt_level)\n",
    "                col_embs = TableUtil.get_col_embs(ave_embs, bs, n_rows, n_cols, table_mask, transformer_col,\n",
    "                                                  self.opt_level)\n",
    "            ave_embs = (row_embs + col_embs) / 2.0\n",
    "        return row_embs, col_embs, n_rows, n_cols\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cat_cls(row_embs, col_embs, n_seed_cols, device):\n",
    "        # Not just colcls concatenated but their average with row_embs concatenated\n",
    "        ave_embs = (row_embs + col_embs) / 2.0\n",
    "        ave_embs = ave_embs[:, 0, 1:, :] # [bs, row having clscol, first_row:all_rows, emb_dim]\n",
    "        bs = ave_embs.shape[0]\n",
    "\n",
    "        cls_embs = ave_embs[:, 0, :]       \n",
    "        for i in range(1, n_seed_cols):\n",
    "            if ave_embs.shape[1] <= i: ## This condition is never met as num clscol embeddings == num_seed_cols\n",
    "                zeros = torch.zeros((bs, 768), device=device)\n",
    "                cls_embs = torch.cat([cls_embs, zeros], dim=1)\n",
    "            else:\n",
    "                cls_embs = torch.cat([cls_embs, ave_embs[:, i, :]], dim=1)\n",
    "        return cls_embs\n",
    "\n",
    "    @staticmethod\n",
    "    def mask_cls_embs(cls_embs, table_info):\n",
    "        ## Function to mask cls embedding based on number of columns / number of seed columns present in table\n",
    "        for k, one_info in enumerate(table_info):\n",
    "            if one_info['num_cols'] == 1:\n",
    "                cls_embs[k, 768:] = 0\n",
    "            elif one_info['num_cols'] == 2:\n",
    "                cls_embs[k, (768 * 2):] = 0\n",
    "        return cls_embs\n",
    "\n",
    "    def validate_seed_cols(self, table_info):\n",
    "        for one_info in table_info:\n",
    "            if one_info['num_cols'] > self.n_seed_cols:\n",
    "                raise ValueError('invalid num cols')\n",
    "\n",
    "    def get_meta(self, table_info):\n",
    "        nrows = [one_info['num_rows'] for one_info in table_info]\n",
    "        ncols = [one_info['num_cols'] for one_info in table_info]\n",
    "        tids = [one_info['table_id'] for one_info in table_info]\n",
    "        return nrows, ncols, tids\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,\n",
    "                table_info: Dict[str, str],\n",
    "                indexed_headers: Dict[str, torch.LongTensor],\n",
    "                indexed_cells: Dict[str, torch.LongTensor],\n",
    "                labels: Optional[torch.LongTensor]) -> Tuple[Optional[torch.Tensor], torch.Tensor]:\n",
    "        \"\"\"\n",
    "\n",
    "        :param table_info: see data/table_info.txt for example\n",
    "        :param indexed_headers:  see data/indexed_headers.txt for example\n",
    "        :param labels: vector of length self.n_classes 0 or 1\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        ## Initialize\n",
    "        self.bert_embedder.eval()\n",
    "        ## TODO : n_seed_col variable not defined in jsonnets loaded.\n",
    "        ## Question : What exactly is n_seed_cols?\n",
    "        self.validate_seed_cols(table_info)\n",
    "        bs, n_rows, n_cols = TableUtil.get_max_row_col(table_info)\n",
    "        nrows, ncols, tids = self.get_meta(table_info)\n",
    "        table_mask = TableUtil.get_table_mask(table_info, bs, n_rows, n_cols, self.device)\n",
    "\n",
    "        ## Prediction Probability\n",
    "        ## TODO : indexed_cells not sent for column population.\n",
    "        ## Question : Why is indexed_cells None for column population?\n",
    "        bert_header, bert_cell = TableUtil.get_bert_emb(indexed_headers, indexed_cells, table_info, bs, n_rows, n_cols,\n",
    "                                                        self.cache_usage, self.bert_embedder, self.cache_util,\n",
    "                                                        self.device)\n",
    "\n",
    "        row_embs, col_embs, n_rows_cls, n_cols_cls = self.get_tabemb(bert_header, bert_cell, n_rows, n_cols, bs,\n",
    "                                                                     table_mask, nrows, ncols) # row_embs.shape : torch.Size([1, 6, 5, 768])\n",
    "        \n",
    "        ## TODO : Updated n_seed_cols before updating this\n",
    "        # To fine-tune TABBIE on this task, we first concatenate the column [CLSCOL] \n",
    "        # embeddings of the seed table into a single vector and pass it through a single linear \n",
    "        # and softmax layer, training with a multi-label classification objective\n",
    "        \n",
    "        cls_embs = self.get_cat_cls(row_embs, col_embs, self.n_seed_cols, self.device) # Concatenate clscol embeddings for seed columns     \n",
    "        cls_embs = self.mask_cls_embs(cls_embs, table_info)\n",
    "        out_prob = self.top_feedforward(cls_embs)\n",
    "\n",
    "        # from this point we have the probabilities for each possible header, we'll do BCE loss (or their original duplicating loss)\n",
    "        if labels is not None:\n",
    "            ## TODO: compute loss            \n",
    "            loss = self.loss(out_prob, labels)\n",
    "        else:\n",
    "            loss = None\n",
    "\n",
    "        return loss, out_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e049d29-b280-4e90-8652-64bd043f9d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afc2fb-de90-4070-b654-9e2de12b52da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9b068d0-bdfe-452f-a85e-71e46c3fb655",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e2bf687-fb37-4c65-90a2-e0a949ab0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = [{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "                  , 'num_rows': 3\n",
    "                  , 'num_cols': 2\n",
    "                  , 'header': ['size', 'japan (cm)']\n",
    "                  , 'cell_labels': None\n",
    "                  , 'col_labels': None\n",
    "                  , 'table_labels': None\n",
    "                  , 'table_data_raw': [['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]\n",
    "                  , 'table': [['size', 'japan (cm)']\n",
    "        , ['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]},{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "                  , 'num_rows': 3\n",
    "                  , 'num_cols': 2\n",
    "                  , 'header': ['size', 'japan (cm)']\n",
    "                  , 'cell_labels': None\n",
    "                  , 'col_labels': None\n",
    "                  , 'table_labels': None\n",
    "                  , 'table_data_raw': [['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]\n",
    "                  , 'table': [['size', 'japan (cm)']\n",
    "        , ['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]},{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "                  , 'num_rows': 3\n",
    "                  , 'num_cols': 2\n",
    "                  , 'header': ['size', 'japan (cm)']\n",
    "                  , 'cell_labels': None\n",
    "                  , 'col_labels': None\n",
    "                  , 'table_labels': None\n",
    "                  , 'table_data_raw': [['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]\n",
    "                  , 'table': [['size', 'japan (cm)']\n",
    "        , ['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]}]\n",
    "\n",
    "indexed_headers = {'bert': {'token_ids': tensor([[[101, 2946, 102, 0, 0, 0],\n",
    "                                                  [101, 2900, 1006, 4642, 1007, 102]]\n",
    "                                                 ,[[101, 2946, 102, 0, 0, 0],\n",
    "                                                  [101, 2900, 1006, 4642, 1007, 102]]\n",
    "                                                 ,[[101, 2946, 102, 0, 0, 0],\n",
    "                                                  [101, 2900, 1006, 4642, 1007, 102]]], device='cuda:0')\n",
    "    , 'mask': tensor([[[True, True, True, False, False, False],\n",
    "                       [True, True, True, True, True, True]],\n",
    "                     [[True, True, True, False, False, False],\n",
    "                       [True, True, True, True, True, True]],\n",
    "                     [[True, True, True, False, False, False],\n",
    "                       [True, True, True, True, True, True]]], device='cuda:0')\n",
    "    , 'type_ids': tensor([[[0, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 0, 0]],\n",
    "                         [[0, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 0, 0]],\n",
    "                         [[0, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 0, 0]]], device='cuda:0')}}\n",
    "\n",
    "indexed_cells = {'bert': {'token_ids': tensor([[[[101, 1020, 1013, 1021, 102],[101, 2603, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1055, 102, 0, 0],\n",
    "                                                 [101, 2484, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1049, 102, 0, 0],\n",
    "                                                 [101, 2423, 102, 0, 0]]],\n",
    "                                              [[[101, 1020, 1013, 1021, 102],[101, 2603, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1055, 102, 0, 0],\n",
    "                                                 [101, 2484, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1049, 102, 0, 0],\n",
    "                                                 [101, 2423, 102, 0, 0]]],\n",
    "                                              [[[101, 1020, 1013, 1021, 102],[101, 2603, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1055, 102, 0, 0],\n",
    "                                                 [101, 2484, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1049, 102, 0, 0],\n",
    "                                                 [101, 2423, 102, 0, 0]]]], device='cuda:0')\n",
    "    , 'mask': tensor([[[[True, True, True, True, True],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]]],\n",
    "                     [[[True, True, True, True, True],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]]],\n",
    "                     [[[True, True, True, True, True],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]]]], device='cuda:0')\n",
    "    , 'type_ids': tensor([[[[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]]],\n",
    "                         [[[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]]],\n",
    "                         [[[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d9a9adc-544e-4439-a7b0-23727f913c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample Input\n",
    "table_info = [{'table_id': 'table-0875-744', 'num_rows': 57, 'num_cols': 2, 'header': ['Edition', 'Year'], 'cell_lables': None, 'col_lables': None, 'table_lables': None, 'table_data_raw': [['1st', '1957'], ['2nd', '1958'], ['3rd', '1959'], ['4th', '1960'], ['5th', '1961'], ['6th', '1962'], ['7th', '1963'], ['8th', '1964'], ['9th', '1965'], ['10th', '1966'], ['11th', '1967'], ['12th', '1968'], ['13th', '1969'], ['14th', '1970'], ['15th', '1971'], ['16th', '1972'], ['17th', '1973'], ['18th', '1974'], ['19th', '1975'], ['20th', '1976'], ['21st', '1977'], ['22nd', '1978'], ['23rd', '1979'], ['24th', '1980'], ['25th', '1981'], ['26th', '1982'], ['27th', '1983'], ['28th', '1984'], ['29th', '1985'], ['30th', '1986'], ['31st', '1987'], ['32nd', '1988'], ['33rd', '1989'], ['34th', '1990'], ['35th', '1991'], ['36th', '1992'], ['37th', '1993'], ['38th', '1994'], ['39th', '1995'], ['40th', '1996'], ['41st', '1997'], ['42nd', '1998'], ['43rd', '1999'], ['44th', '2000'], ['45th', '2001'], ['46th', '2002'], ['47th', '2003'], ['48th', '2004'], ['49th', '2005'], ['50th', '2006'], ['—', '2007'], ['51st', '2008'], ['52nd', '2009'], ['53rd', '2010'], ['54th', '2011'], ['55th', '2012'], ['56th', '2013']], 'table': [['Edition', 'Year'], ['1st', '1957'], ['2nd', '1958'], ['3rd', '1959'], ['4th', '1960'], ['5th', '1961'], ['6th', '1962'], ['7th', '1963'], ['8th', '1964'], ['9th', '1965'], ['10th', '1966'], ['11th', '1967'], ['12th', '1968'], ['13th', '1969'], ['14th', '1970'], ['15th', '1971'], ['16th', '1972'], ['17th', '1973'], ['18th', '1974'], ['19th', '1975'], ['20th', '1976'], ['21st', '1977'], ['22nd', '1978'], ['23rd', '1979'], ['24th', '1980'], ['25th', '1981'], ['26th', '1982'], ['27th', '1983'], ['28th', '1984'], ['29th', '1985'], ['30th', '1986'], ['31st', '1987'], ['32nd', '1988'], ['33rd', '1989'], ['34th', '1990'], ['35th', '1991'], ['36th', '1992'], ['37th', '1993'], ['38th', '1994'], ['39th', '1995'], ['40th', '1996'], ['41st', '1997'], ['42nd', '1998'], ['43rd', '1999'], ['44th', '2000'], ['45th', '2001'], ['46th', '2002'], ['47th', '2003'], ['48th', '2004'], ['49th', '2005'], ['50th', '2006'], ['—', '2007'], ['51st', '2008'], ['52nd', '2009'], ['53rd', '2010'], ['54th', '2011'], ['55th', '2012'], ['56th', '2013']]}]\n",
    "\n",
    "indexed_headers = {'bert': {'token_ids': tensor([[[3179],\n",
    "         [2095]]], device='cuda:0'), 'mask': tensor([[[True],\n",
    "         [True]]], device='cuda:0'), 'type_ids': tensor([[[0],\n",
    "         [0]]], device='cuda:0')}}\n",
    "\n",
    "indexed_cells = {'bert': {'token_ids': tensor([[[[ 3083,     0],\n",
    "          [ 3890,     0]],\n",
    "\n",
    "         [[ 3416,     0],\n",
    "          [ 3845,     0]],\n",
    "\n",
    "         [[ 3822,     0],\n",
    "          [ 3851,     0]],\n",
    "\n",
    "         [[ 4343,     0],\n",
    "          [ 3624,     0]],\n",
    "\n",
    "         [[ 4833,     0],\n",
    "          [ 3777,     0]],\n",
    "\n",
    "         [[ 5351,     0],\n",
    "          [ 3705,     0]],\n",
    "\n",
    "         [[ 5504,     0],\n",
    "          [ 3699,     0]],\n",
    "\n",
    "         [[ 5893,     0],\n",
    "          [ 3546,     0]],\n",
    "\n",
    "         [[ 6280,     0],\n",
    "          [ 3551,     0]],\n",
    "\n",
    "         [[ 6049,     0],\n",
    "          [ 3547,     0]],\n",
    "\n",
    "         [[ 6252,     0],\n",
    "          [ 3476,     0]],\n",
    "\n",
    "         [[ 5940,     0],\n",
    "          [ 3380,     0]],\n",
    "\n",
    "         [[ 6122,     0],\n",
    "          [ 3440,     0]],\n",
    "\n",
    "         [[ 6400,     0],\n",
    "          [ 3359,     0]],\n",
    "\n",
    "         [[ 6286,     0],\n",
    "          [ 3411,     0]],\n",
    "\n",
    "         [[ 5767,     0],\n",
    "          [ 3285,     0]],\n",
    "\n",
    "         [[ 5550,     0],\n",
    "          [ 3381,     0]],\n",
    "\n",
    "         [[ 4985,     0],\n",
    "          [ 3326,     0]],\n",
    "\n",
    "         [[ 3708,     0],\n",
    "          [ 3339,     0]],\n",
    "\n",
    "         [[ 3983,     0],\n",
    "          [ 3299,     0]],\n",
    "\n",
    "         [[ 7398,     0],\n",
    "          [ 3355,     0]],\n",
    "\n",
    "         [[13816,     0],\n",
    "          [ 3301,     0]],\n",
    "\n",
    "         [[13928,     0],\n",
    "          [ 3245,     0]],\n",
    "\n",
    "         [[13386,     0],\n",
    "          [ 3150,     0]],\n",
    "\n",
    "         [[10965,     0],\n",
    "          [ 3261,     0]],\n",
    "\n",
    "         [[14935,     0],\n",
    "          [ 3196,     0]],\n",
    "\n",
    "         [[15045,     0],\n",
    "          [ 3172,     0]],\n",
    "\n",
    "         [[15538,     0],\n",
    "          [ 3118,     0]],\n",
    "\n",
    "         [[16318,     0],\n",
    "          [ 3106,     0]],\n",
    "\n",
    "         [[13293,     0],\n",
    "          [ 3069,     0]],\n",
    "\n",
    "         [[17089,     0],\n",
    "          [ 3055,     0]],\n",
    "\n",
    "         [[20628,     0],\n",
    "          [ 2997,     0]],\n",
    "\n",
    "         [[20883,     0],\n",
    "          [ 2960,     0]],\n",
    "\n",
    "         [[20460,     0],\n",
    "          [ 2901,     0]],\n",
    "\n",
    "         [[20198,     0],\n",
    "          [ 2889,     0]],\n",
    "\n",
    "         [[21460,     0],\n",
    "          [ 2826,     0]],\n",
    "\n",
    "         [[23027,     0],\n",
    "          [ 2857,     0]],\n",
    "\n",
    "         [[22051,     0],\n",
    "          [ 2807,     0]],\n",
    "\n",
    "         [[22702,     0],\n",
    "          [ 2786,     0]],\n",
    "\n",
    "         [[16541,     0],\n",
    "          [ 2727,     0]],\n",
    "\n",
    "         [[24233,     0],\n",
    "          [ 2722,     0]],\n",
    "\n",
    "         [[21373,     0],\n",
    "          [ 2687,     0]],\n",
    "\n",
    "         [[25747,     0],\n",
    "          [ 2639,     0]],\n",
    "\n",
    "         [[26409,     0],\n",
    "          [ 2456,     0]],\n",
    "\n",
    "         [[24634,     0],\n",
    "          [ 2541,     0]],\n",
    "\n",
    "         [[27990,     0],\n",
    "          [ 2526,     0]],\n",
    "\n",
    "         [[28243,     0],\n",
    "          [ 2494,     0]],\n",
    "\n",
    "         [[27787,     0],\n",
    "          [ 2432,     0]],\n",
    "\n",
    "         [[25726,     0],\n",
    "          [ 2384,     0]],\n",
    "\n",
    "         [[12951,     0],\n",
    "          [ 2294,     0]],\n",
    "\n",
    "         [[ 1517,     0],\n",
    "          [ 2289,     0]],\n",
    "\n",
    "         [[26017,     0],\n",
    "          [ 2263,     0]],\n",
    "\n",
    "         [[26898,     0],\n",
    "          [ 2268,     0]],\n",
    "\n",
    "         [[ 5187,  4103],\n",
    "          [ 2230,     0]],\n",
    "\n",
    "         [[29570,     0],\n",
    "          [ 2249,     0]],\n",
    "\n",
    "         [[29075,     0],\n",
    "          [ 2262,     0]],\n",
    "\n",
    "         [[29087,     0],\n",
    "          [ 2286,     0]]]], device='cuda:0'), 'mask': tensor([[[[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True,  True],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]]]], device='cuda:0'), 'type_ids': tensor([[[[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "110e8394-474f-400d-a60f-63a385df594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing TableembedderTorch module\n",
    "from table_embedder.models.finetune_entitables_cp import TableEmbedder, TableEmbedderHypers\n",
    "hypers = TableEmbedderHypers()\n",
    "model = TableEmbedder(hypers).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c410ff8-ac51-4fd5-9dca-bc92d270cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m(142)\u001b[0;36mget_tabemb\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 142 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m(143)\u001b[0;36mget_tabemb\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    141 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 143 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    145 \u001b[0;31m                \u001b[0;31m# table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  row_pos_ids.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  row_pos_embs.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n_rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.hypers.num_max_row_pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/scratch/gypsum-gpu140/3016139/ipykernel_878133/1191245428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexed_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, table_info, indexed_headers, indexed_cells, labels)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         row_embs, col_embs, n_rows_cls, n_cols_cls = self.get_tabemb(bert_header, bert_cell, n_rows, n_cols, bs,\n\u001b[0;32m--> 222\u001b[0;31m                                                                      table_mask, nrows, ncols)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# To fine-tune TABBIE on this task, we first concatenate the column [CLSCOL]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m in \u001b[0;36mget_tabemb\u001b[0;34m(self, bert_header, bert_data, n_rows, n_cols, bs, table_mask, nrows, ncols)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;31m# table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m in \u001b[0;36mget_tabemb\u001b[0;34m(self, bert_header, bert_data, n_rows, n_cols, bs, table_mask, nrows, ncols)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;31m# table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, prob = model(table_info,indexed_headers, indexed_cells, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18754aee-6e77-4684-a63f-f05960fd4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc74d72-5394-40a1-abc6-966c421f6244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db50bb4-56c2-431f-b2b2-0e6c2dda5fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34af98d-13f6-43a9-9f71-b21e146c4038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6047c7-a06b-4e2e-bdd5-c2af4263f47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0c777-8731-4629-b109-a5535d8f8ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634678e8-2faa-4e52-b940-4577720e9290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e49178-68b5-4363-9e18-5092f228578c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469d21a7-37c9-46ce-b6d0-e048183bd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the torch Model\n",
    "import torch\n",
    "model_namedparam = torch.load('/work/arnaik_umass_edu/model_named.pt')\n",
    "model_param = torch.load('/work/arnaik_umass_edu/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8734c73-4a98-414d-a08e-de09c0d9334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e2afa0-c16c-42af-a180-26d9042daf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_namedparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437eebe3-0923-4707-9f77-7f6b2e56fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af9c502-ff38-477e-b6ee-6a32862f1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.load('/work/arnaik_umass_edu/tabbie/data/clsrow.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "761e9c2e-b51a-4bdc-be63-0c3b54104e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89da88b-4e20-49f8-ad2f-ebfa22946745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03870d-daaa-4224-b8f6-be0117e8fe47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa0db6-ff9b-4dee-ba29-a8d7b4457284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce761a-ea4b-467b-b033-d80e115254b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134989f5-65cb-40a3-9b05-5b5507fa41f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b190310-13fd-4cca-9b98-e01b612ed196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c060a-d810-4ebd-9adc-10981f39d003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63357b-465a-4b37-bd43-6bd3be2ce36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5d9012-0674-4fe4-84fc-d5b4aa9f30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = [{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "               , 'num_rows': 4\n",
    "               , 'num_cols': 7\n",
    "               , 'header': ['size', 'us', 'type', 'china', 'gaa', 'eu', 'years']\n",
    "               , 'cell_labels': None\n",
    "               , 'col_labels': [2, 4, 6]\n",
    "               , 'table_labels': None\n",
    "               , 'table_data_raw': [['xs', '6/7', '9.125', '235', '23', '36-37', '4']\n",
    "                                    , ['s', '7/8', '9.5', '245', '24', '38-39', '5']\n",
    "                                    , ['m', '8/9', '9.875', '255', '25', '39-40', '6']\n",
    "                                    , ['l', '9/10', '10.375', '265', '26', '40-41', '7']]\n",
    "               , 'table': [['size', 'us', 'type', 'china', 'gaa', 'eu', 'years']\n",
    "                           , ['xs', '6/7', '9.125', '235', '23', '36-37', '4']\n",
    "                           , ['s', '7/8', '9.5', '245', '24', '38-39', '5']\n",
    "                           , ['m', '8/9', '9.875', '255', '25', '39-40', '6']\n",
    "                           , ['l', '9/10', '10.375', '265', '26', '40-41', '7']]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82c3529-e4cb-4eac-a448-ed3eb6472027",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_headers = {'bert': {'token_ids': tensor([[[  101,  2946,   102],\n",
    "         [  101,  2149,   102],\n",
    "         [  101,  2828,   102],\n",
    "         [  101,  2859,   102],\n",
    "         [  101, 19930,   102],\n",
    "         [  101,  7327,   102],\n",
    "         [  101,  2086,   102]]], device='cuda:0')\n",
    ", 'mask': tensor([[[True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d92c34-a4f0-43ab-b3c2-d8130626a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_cells = {'bert': {'token_ids': tensor([[[[  101,  1060,  2015,   102,     0],\n",
    "          [  101,  1020,  1013,  1021,   102],\n",
    "          [  101,  1023,  1012,  8732,   102],\n",
    "          [  101, 17825,   102,     0,     0],\n",
    "          [  101,  2603,   102,     0,     0],\n",
    "          [  101,  4029,  1011,  4261,   102],\n",
    "          [  101,  1018,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1055,   102,     0,     0],\n",
    "          [  101,  1021,  1013,  1022,   102],\n",
    "          [  101,  1023,  1012,  1019,   102],\n",
    "          [  101, 21005,   102,     0,     0],\n",
    "          [  101,  2484,   102,     0,     0],\n",
    "          [  101,  4229,  1011,  4464,   102],\n",
    "          [  101,  1019,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1049,   102,     0,     0],\n",
    "          [  101,  1022,  1013,  1023,   102],\n",
    "          [  101,  1023,  1012, 27658,   102],\n",
    "          [  101, 20637,   102,     0,     0],\n",
    "          [  101,  2423,   102,     0,     0],\n",
    "          [  101,  4464,  1011,  2871,   102],\n",
    "          [  101,  1020,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1048,   102,     0,     0],\n",
    "          [  101,  1023,  1013,  2184,   102],\n",
    "          [  101,  2184,  1012, 18034,   102],\n",
    "          [  101, 20549,   102,     0,     0],\n",
    "          [  101,  2656,   102,     0,     0],\n",
    "          [  101,  2871,  1011,  4601,   102],\n",
    "          [  101,  1021,   102,     0,     0]]]], device='cuda:0')\n",
    ", 'mask': tensor([[[[ True,  True,  True,  True, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43d746-265f-4f1f-93a4-8409a15156cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39376381-4b6f-4767-b667-68c3a74d4350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb6dc9-46ea-4b1e-b91c-8bb8418e1c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c81d12-512f-4130-8c17-8a5cd81d6753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f000a1-ef55-46f5-b694-7faaf5c0de06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aedbf86-e619-4f09-9363-a1d61db4b7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d9dab-70f9-4635-b7d7-e3d2501c345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547fea9-2278-417a-b52a-3461dce527b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bcf90-a702-4564-aaf6-f1b1842a99dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9e603-43b5-493f-ad3d-23e3241e1aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568a1e9-9376-43f8-ba92-9e885ae33e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878f4b9-ef14-4875-b4cd-341186dc15c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee20e0-de16-454f-98b6-4946fb92055c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684b50e-a512-4313-a775-f919d7b378ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37ab16-73c2-47fa-ac6c-136328712e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99ad85-c66d-4a02-8aa2-29f876859401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125ad12-c839-48ff-870f-0beec67896be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78073863-f787-4dc0-86b5-53f9301d0689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce72e4-2f44-4ce7-884f-fbc03fca4e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd638709-f91c-4222-a621-800f1db75292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44678242-ab7e-41d9-bc64-a83242cf045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1dd9a-970d-43c6-8ae1-4e08b3570165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c18204-64e5-4b6d-b953-814ae6aa08f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b70c6-2221-4568-9b84-9af8307dcd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-vinyl",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-table_emb_py37)",
   "language": "python",
   "name": "conda-env-.conda-table_emb_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
