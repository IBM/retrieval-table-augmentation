{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spectacular-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Optional, Tuple\n",
    "from overrides import overrides\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scripts.row_pop import RowPop\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from allennlp.nn import util\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules import FeedForward, TextFieldEmbedder, Seq2VecEncoder\n",
    "from allennlp.nn import InitializerApplicator, RegularizerApplicator\n",
    "from allennlp.training.metrics.categorical_accuracy import CategoricalAccuracy\n",
    "# from allennlp.modules.token_embedders import PretrainedBertEmbedder\n",
    "from table_embedder.models.lib.bert_token_embedder import PretrainedBertEmbedder\n",
    "from allennlp.models.archival import load_archive\n",
    "\n",
    "from table_embedder.models.embedder_util import TableUtil\n",
    "from table_embedder.models.lib.stacked_self_attention import StackedSelfAttentionEncoder\n",
    "# from lib.stacked_self_attention import StackedSelfAttentionEncoder\n",
    "\n",
    "from table_embedder.models.cache_util import CacheUtil\n",
    "#from .lib.masked_ff import MaskedFeedForward\n",
    "# torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "\n",
    "\n",
    "from table_embedder.models.cache_util import CacheUtil\n",
    "\n",
    "from torch import nn\n",
    "from torch import tensor\n",
    "import pdb\n",
    "\n",
    "from torch_util.hypers_base import HypersBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff6e28d8-baa5-4066-9cf6-0ad0f36f28d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableEmbedderHypers(HypersBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.num_max_row_pos = 31\n",
    "        self.num_max_col_pos = 25\n",
    "        self.n_classes = 127656  # FIXME: we'll update this, since I can't reproduce\n",
    "        self.n_seed_rows = 2\n",
    "        # where we have clscol.npy  clsrow.npy\n",
    "        self.saved_table_cls_dir = '/work/arnaik_umass_edu/tabbie/data'  # OR on CCC: '/dccstor/few-shot-rel/TableAugmentation/tabbie/data'\n",
    "        self.model_file = '/work/arnaik_umass_edu/model_named.pt'\n",
    "        \n",
    "    def _post_init(self):\n",
    "        super()._post_init()\n",
    "        self.per_gpu_train_batch_size = 1\n",
    "        if self.full_train_batch_size < self.world_size or self.full_train_batch_size % self.world_size != 0:\n",
    "            raise ValueError(f'full_train_batch_size ({self.full_train_batch_size} '\n",
    "                             f'must be a multiple of world_size ({self.world_size})')\n",
    "        self.gradient_accumulation_steps = self.full_train_batch_size // self.world_size        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d95bd9e-5b25-4484-9aef-8b0e3a11f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88261272-d5be-4873-b356-a85bcf7826fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = [{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "               , 'num_rows': 2\n",
    "               , 'num_cols': 7\n",
    "               , 'header': ['size', 'us', 'type', 'china', 'gaa', 'eu', 'years']\n",
    "               , 'cell_labels': None\n",
    "               , 'col_labels': None\n",
    "               , 'table_labels': None\n",
    "               , 'table_data_raw': [['xs', '6/7', '9.125', '235', '23', '36-37', '4']\n",
    "                                    , ['s', '7/8', '9.5', '245', '24', '38-39', '5']]\n",
    "               , 'table': [['size', 'us', 'type', 'china', 'gaa', 'eu', 'years']\n",
    "                           , ['xs', '6/7', '9.125', '235', '23', '36-37', '4']\n",
    "                           , ['s', '7/8', '9.5', '245', '24', '38-39', '5']]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdf295b8-99d6-4574-8029-8b8a4bab821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_headers = {'bert': {'token_ids': tensor([[[  101,  2946,   102],\n",
    "         [  101,  2149,   102],\n",
    "         [  101,  2828,   102],\n",
    "         [  101,  2859,   102],\n",
    "         [  101, 19930,   102],\n",
    "         [  101,  7327,   102],\n",
    "         [  101,  2086,   102]]], device='cuda:0')\n",
    ", 'mask': tensor([[[True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0cdee08-c45c-44cd-9dea-53ed6d72be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_cells = {'bert': {'token_ids': tensor([[[[  101,  1060,  2015,   102,     0],\n",
    "          [  101,  1020,  1013,  1021,   102],\n",
    "          [  101,  1023,  1012,  8732,   102],\n",
    "          [  101, 17825,   102,     0,     0],\n",
    "          [  101,  2603,   102,     0,     0],\n",
    "          [  101,  4029,  1011,  4261,   102],\n",
    "          [  101,  1018,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1055,   102,     0,     0],\n",
    "          [  101,  1021,  1013,  1022,   102],\n",
    "          [  101,  1023,  1012,  1019,   102],\n",
    "          [  101, 21005,   102,     0,     0],\n",
    "          [  101,  2484,   102,     0,     0],\n",
    "          [  101,  4229,  1011,  4464,   102],\n",
    "          [  101,  1019,   102,     0,     0]]]], device='cuda:0')\n",
    ", 'mask': tensor([[[[ True,  True,  True,  True, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409389d4-e262-4a2e-b8eb-ad006a33bccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7234fa7-7e1d-4a45-b728-0ce261764342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, dict, dict)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(table_info), type(indexed_headers), type(indexed_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19559348-2ea8-4082-ac7f-c054fb0f1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypers = TableEmbedderHypers()\n",
    "model = TableEmbedderTorch(hypers).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acbaba10-87a9-41ad-8dfc-22c6c9fb8eaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/scratch/gypsum-gpu127/3053032/ipykernel_20844/1191245428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexed_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gypsum-gpu127/3053032/ipykernel_20844/2665689734.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, table_info, indexed_headers, indexed_cells, labels)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# label/prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mlabels_1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mlabels_1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampled_labels_1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/gypsum-gpu127/3053032/ipykernel_20844/2665689734.py\u001b[0m in \u001b[0;36mget_labels\u001b[0;34m(table_info)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mlabels_1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mone_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable_info\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mrow_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0mrow_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'label_idx'"
     ]
    }
   ],
   "source": [
    "loss, prob = model(table_info,indexed_headers, indexed_cells, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e976560-0b05-4346-b163-14cc981d0c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableEmbedder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hypers: TableEmbedderHypers) -> None:\n",
    "        super().__init__()\n",
    "        self.hypers = hypers\n",
    "        \n",
    "        self.row_pos_embedding = Embedding(num_embeddings=self.hypers.num_max_row_pos, embedding_dim=768)\n",
    "        self.col_pos_embedding = Embedding(num_embeddings=self.hypers.num_max_col_pos, embedding_dim=768)        \n",
    "        \n",
    "        # TODO: Create the feedforward layer for row population\n",
    "        self.top_feedforward = nn.Linear(768*self.hypers.n_seed_rows, self.hypers.n_classes)\n",
    "        self.Dropout = nn.Dropout(p = 0.0) # At the moment Dropout not used as only one-layer network\n",
    "\n",
    "        # # self.row_feedforward = row_feedforward # NOTE : Not used in forward pass\n",
    "        # self.feedforward = feedforward # NOTE : Feedforward layer but not used in forward pass\n",
    "        # self.compose_ff = compose_ff # NOTE : Feedforward layer but not used in forward pass\n",
    "        \n",
    "        self.bert_embedder = PretrainedBertEmbedder(pretrained_model='bert-base-uncased', top_layer_only=True)\n",
    "        self.transformer_col1 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col2 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col3 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col4 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col5 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col6 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col7 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col8 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col9 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col10 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col11 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_col12 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "\n",
    "        self.transformer_row1 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row2 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row3 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row4 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row5 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row6 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row7 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row8 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row9 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row10 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row11 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "        self.transformer_row12 = StackedSelfAttentionEncoder(768, 768, 768, 3072, 1, 12, False)\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        self.cache_usage = None\n",
    "\n",
    "        # TODO: try these as plain parameters, initialized from the saved clscol and clsrow embeddings\n",
    "        self.cls_col = np.load(os.path.join(hypers.saved_table_cls_dir, 'clscol.npy'))\n",
    "        self.cls_row = np.load(os.path.join(hypers.saved_table_cls_dir, 'clsrow.npy'))\n",
    "\n",
    "        self.opt_level = 'O0'\n",
    "\n",
    "        ## TODO : Updated the 'getenv'\n",
    "        if self.cache_usage is not None:\n",
    "            self.cache_util = CacheUtil(self.cache_usage, os.getenv(\"cell_db_path\"))\n",
    "        else:\n",
    "            self.cache_util = None\n",
    "\n",
    "        self.init_weight() # As feedforward layer is not present in the archieved model rather than using 'load_state_dict' still updating the model via a function\n",
    "        \n",
    "        # # TODO : Check what the load_label function does\n",
    "        # self.label = RowPop.load_label(os.getenv('label_path'), key='index')\n",
    "\n",
    "    def init_weight(self):\n",
    "        model_parameters = dict(self.named_parameters())\n",
    "        archived_parameters = torch.load(self.hypers.model_file) # Archieved weights of feedforward layers discarded.\n",
    "        for name, weights in archived_parameters.items():\n",
    "            if name in model_parameters:\n",
    "                new_weights = weights.data\n",
    "                model_parameters[name].data.copy_(new_weights)\n",
    "\n",
    "    def get_tabemb(self, bert_header, bert_data, n_rows, n_cols, bs, table_mask, nrows, ncols):\n",
    "        row_pos_ids = torch.arange(0, self.hypers.num_max_row_pos, device=self.device, dtype=torch.long)\n",
    "        col_pos_ids = torch.arange(0, self.hypers.num_max_col_pos, device=self.device, dtype=torch.long)\n",
    "\n",
    "        n_rows += 1  # row CLS\n",
    "        n_cols += 1  # col CLS\n",
    "        cls_col = torch.from_numpy(copy.deepcopy(self.cls_col)).to(device=self.device)\n",
    "        cls_row = torch.from_numpy(copy.deepcopy(self.cls_row)).to(device=self.device)\n",
    "        row_pos_embs = self.row_pos_embedding(row_pos_ids[:n_rows+1])\n",
    "        col_pos_embs = self.col_pos_embedding(col_pos_ids[:n_cols])\n",
    "\n",
    "        for i in range(1, 13):\n",
    "            transformer_row = getattr(self, 'transformer_row{}'.format(str(i)))\n",
    "            transformer_col = getattr(self, 'transformer_col{}'.format(str(i)))\n",
    "            if i == 1:\n",
    "                bert_data = TableUtil.add_cls_tokens(bert_header, bert_data, cls_row, cls_col, bs, n_rows, n_cols)\n",
    "                bert_data += row_pos_embs.expand((bs, n_cols, n_rows + 1, 768)).permute(0, 2, 1, 3).expand_as(bert_data)\n",
    "                bert_data += col_pos_embs.expand((bs, n_rows + 1, n_cols, 768)).expand_as(bert_data)\n",
    "                # table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\n",
    "                table_mask = TableUtil.add_cls_mask(table_mask, bs, n_rows, n_cols, self.device, nrows, ncols)\n",
    "                col_embs = TableUtil.get_col_embs(bert_data, bs, n_rows, n_cols, table_mask, transformer_col, self.opt_level)\n",
    "                row_embs = TableUtil.get_row_embs(bert_data, bs, n_rows, n_cols, table_mask, transformer_row, self.opt_level)\n",
    "            else:\n",
    "                row_embs = TableUtil.get_row_embs(ave_embs, bs, n_rows, n_cols, table_mask, transformer_row, self.opt_level)\n",
    "                col_embs = TableUtil.get_col_embs(ave_embs, bs, n_rows, n_cols, table_mask, transformer_col, self.opt_level)\n",
    "            ave_embs = (row_embs + col_embs) / 2.0\n",
    "        return row_embs, col_embs, n_rows, n_cols\n",
    "\n",
    "    # @staticmethod\n",
    "    # def get_labels(table_info):\n",
    "    #     labels = []\n",
    "    #     labels_1d = []\n",
    "    #     for one_info in table_info:\n",
    "    #         row_labels = list(set(copy.deepcopy(one_info['label_idx'])))\n",
    "    #         if 0 in row_labels:\n",
    "    #             row_labels.remove(0)\n",
    "    #         labels.append(row_labels)\n",
    "    #         for elem in row_labels:\n",
    "    #             labels_1d.append(elem)\n",
    "    #     return labels_1d, labels\n",
    "\n",
    "    def pred_prob(self, cell_embs, labels, mask):\n",
    "        out_prob = self.top_feedforward(cell_embs, mask)\n",
    "        out_prob_1d = []\n",
    "        for k, one_prob in enumerate(out_prob):\n",
    "            # out_prob_1d.append(one_prob.expand(len(labels[k]), self.n_classes))\n",
    "            out_prob_1d.append(one_prob.expand(len(labels[k]), out_prob.shape[1]))\n",
    "        out_prob_1d = torch.cat(out_prob_1d, dim=0)\n",
    "        return out_prob_1d, out_prob\n",
    "\n",
    "    @staticmethod\n",
    "    def add_metadata(table_info, output_dict, pred_labels, pred_labels_name):\n",
    "        data_dict = {'pred_labels': pred_labels, 'pred_labels_name': pred_labels_name}\n",
    "        for one_info in table_info:\n",
    "            for k, v in one_info.items():\n",
    "                data_dict[k] = data_dict.get(k, [])\n",
    "                data_dict[k].append(v)\n",
    "        output_dict.update(data_dict)\n",
    "        return output_dict\n",
    "\n",
    "    def get_pred_labels(self, out_prob, labels, top_k=-1):\n",
    "        pred_labels = []\n",
    "        pred_labels_name = []\n",
    "        for k, row_labels in enumerate(labels):\n",
    "            n_pred = len(row_labels) if top_k == -1 else top_k\n",
    "            pred_row_labels = out_prob[k][1:].argsort(dim=0, descending=True)[:n_pred].cpu().numpy()  # out_prob[0]: blank header\n",
    "            pred_row_labels = [elem+1 for elem in pred_row_labels]  # add idx to 1 (for out_prob[0])\n",
    "            pred_labels.append(pred_row_labels)\n",
    "            pred_labels_name.append([self.label[elem] for elem in pred_row_labels])\n",
    "        return pred_labels, pred_labels_name\n",
    "\n",
    "    def sample_labels(self, labels_1d):\n",
    "        # sampled label\n",
    "        mask_bool = torch.cuda.FloatTensor(self.n_classes).uniform_() > 0.8\n",
    "        mask = torch.tensor(mask_bool, dtype=torch.int)\n",
    "        mask[labels_1d] = 2\n",
    "\n",
    "        # target label\n",
    "        new_labels = mask[mask!=0]\n",
    "        new_labels[new_labels==1] = 0\n",
    "        new_labels[new_labels==2] = 1\n",
    "\n",
    "        # old_new label map\n",
    "        old_idx = (mask==2).nonzero()\n",
    "        new_idx = (new_labels==1).nonzero()\n",
    "        idx_map = {}\n",
    "        for k, idx in enumerate(old_idx):\n",
    "            idx_map[int(idx)] = int(new_idx[k])\n",
    "        new_labels_1d = torch.autograd.Variable(labels_1d.clone())\n",
    "        for k, idx in enumerate(labels_1d):\n",
    "            new_labels_1d[k] = idx_map[int(idx)]\n",
    "        return mask, new_labels_1d\n",
    "\n",
    "    def validate_seed_rows(self, table_info):\n",
    "        for one_info in table_info:\n",
    "            if one_info['num_rows'] > self.n_seed_rows:\n",
    "                raise ValueError('invalid num rows')\n",
    "\n",
    "    def get_meta(self, table_info):\n",
    "        nrows = [one_info['num_rows'] for one_info in table_info]\n",
    "        ncols = [one_info['num_cols'] for one_info in table_info]\n",
    "        tids = [one_info['table_id'] for one_info in table_info]\n",
    "        return nrows, ncols, tids\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,\n",
    "                table_info: Dict[str, str],\n",
    "                indexed_headers: Dict[str, torch.LongTensor],\n",
    "                indexed_cells: Dict[str, torch.LongTensor],\n",
    "                labels: Optional[torch.FloatTensor]) -> Tuple[Optional[torch.Tensor], torch.Tensor]:\n",
    "        \"\"\"\n",
    "\n",
    "        :param table_info: see data/table_info.txt for example\n",
    "        :param indexed_headers:  see data/indexed_headers.txt for example\n",
    "        :param indexed_cells: see data/indexed_headers.txt for example\n",
    "        :param labels: 0 or 1 tensor with shape: bs x self.hypers.n_classes\n",
    "        :return: loss and output probabilities (for each possible header)\n",
    "        \"\"\"\n",
    "        \n",
    "        # initialize\n",
    "        self.bert_embedder.eval()\n",
    "        # self.validate_seed_rows(table_info)\n",
    "        bs, n_rows, n_cols = TableUtil.get_max_row_col(table_info)\n",
    "        nrows, ncols, tids = self.get_meta(table_info)\n",
    "        table_mask = TableUtil.get_table_mask(table_info, bs, n_rows, n_cols, self.device)\n",
    "\n",
    "        # pred prob\n",
    "        bert_header, bert_cell = TableUtil.get_bert_emb(indexed_headers, indexed_cells, table_info, bs, n_rows, n_cols, self.cache_usage, self.bert_embedder, self.cache_util, self.device)\n",
    "        row_embs, col_embs, n_rows_cls, n_cols_cls = self.get_tabemb(bert_header, bert_cell, n_rows, n_cols, bs, table_mask, nrows, ncols)\n",
    "        \n",
    "        cell_embs = (col_embs[:, 0, 1, :] + row_embs[:, 0, 1, :]) / 2.0\n",
    "\n",
    "        # label/prob\n",
    "#        labels_1d, labels = self.get_labels(table_info)\n",
    "        labels = torch.LongTensor(labels).to(device=self.device)\n",
    "        mask, sampled_labels = self.sample_labels(labels)\n",
    "\n",
    "        if not self.training:\n",
    "            mask = torch.ones(mask.shape, dtype=torch.int)\n",
    "            sampled_labels_1d = labels_1d\n",
    "\n",
    "        out_prob_1d, out_prob = self.pred_prob(cell_embs, labels, mask)\n",
    "\n",
    "        # calc loss func\n",
    "        # loss = self.loss_func(out_prob_1d[:, mask.nonzero().flatten()], sampled_labels_1d)\n",
    "        loss = self.loss(out_prob_1d, sampled_labels_1d)\n",
    "\n",
    "        # pred labels\n",
    "        # pred_labels, pred_labels_name = self.get_pred_labels(out_prob, labels)\n",
    "        # out_prob_cp = self.mod_out_prob(out_prob_1d, pred_labels)\n",
    "\n",
    "        # if random.random() < 0.01:\n",
    "        #     for k, one_info in enumerate(table_info):\n",
    "        #         print()\n",
    "        #         print(one_info['seed_col0'])\n",
    "        #         print(one_info['label'])\n",
    "        #         print(pred_labels_name[k])\n",
    "\n",
    "        output_dict = {'loss': loss}\n",
    "\n",
    "        if not self.training:\n",
    "            pred_labels, pred_labels_name = self.get_pred_labels(out_prob, labels, top_k=500)\n",
    "            output_dict = self.add_metadata(table_info, output_dict, pred_labels, pred_labels_name)\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e049d29-b280-4e90-8652-64bd043f9d62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79afc2fb-de90-4070-b654-9e2de12b52da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b068d0-bdfe-452f-a85e-71e46c3fb655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e2bf687-fb37-4c65-90a2-e0a949ab0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = [{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "                  , 'num_rows': 3\n",
    "                  , 'num_cols': 2\n",
    "                  , 'header': ['size', 'japan (cm)']\n",
    "                  , 'cell_labels': None\n",
    "                  , 'col_labels': None\n",
    "                  , 'table_labels': None\n",
    "                  , 'table_data_raw': [['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]\n",
    "                  , 'table': [['size', 'japan (cm)']\n",
    "        , ['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]},{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "                  , 'num_rows': 3\n",
    "                  , 'num_cols': 2\n",
    "                  , 'header': ['size', 'japan (cm)']\n",
    "                  , 'cell_labels': None\n",
    "                  , 'col_labels': None\n",
    "                  , 'table_labels': None\n",
    "                  , 'table_data_raw': [['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]\n",
    "                  , 'table': [['size', 'japan (cm)']\n",
    "        , ['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]},{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "                  , 'num_rows': 3\n",
    "                  , 'num_cols': 2\n",
    "                  , 'header': ['size', 'japan (cm)']\n",
    "                  , 'cell_labels': None\n",
    "                  , 'col_labels': None\n",
    "                  , 'table_labels': None\n",
    "                  , 'table_data_raw': [['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]\n",
    "                  , 'table': [['size', 'japan (cm)']\n",
    "        , ['6/7', '23']\n",
    "        , ['s', '24']\n",
    "        , ['m', '25']]}]\n",
    "\n",
    "indexed_headers = {'bert': {'token_ids': tensor([[[101, 2946, 102, 0, 0, 0],\n",
    "                                                  [101, 2900, 1006, 4642, 1007, 102]]\n",
    "                                                 ,[[101, 2946, 102, 0, 0, 0],\n",
    "                                                  [101, 2900, 1006, 4642, 1007, 102]]\n",
    "                                                 ,[[101, 2946, 102, 0, 0, 0],\n",
    "                                                  [101, 2900, 1006, 4642, 1007, 102]]], device='cuda:0')\n",
    "    , 'mask': tensor([[[True, True, True, False, False, False],\n",
    "                       [True, True, True, True, True, True]],\n",
    "                     [[True, True, True, False, False, False],\n",
    "                       [True, True, True, True, True, True]],\n",
    "                     [[True, True, True, False, False, False],\n",
    "                       [True, True, True, True, True, True]]], device='cuda:0')\n",
    "    , 'type_ids': tensor([[[0, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 0, 0]],\n",
    "                         [[0, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 0, 0]],\n",
    "                         [[0, 0, 0, 0, 0, 0],\n",
    "                           [0, 0, 0, 0, 0, 0]]], device='cuda:0')}}\n",
    "\n",
    "indexed_cells = {'bert': {'token_ids': tensor([[[[101, 1020, 1013, 1021, 102],[101, 2603, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1055, 102, 0, 0],\n",
    "                                                 [101, 2484, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1049, 102, 0, 0],\n",
    "                                                 [101, 2423, 102, 0, 0]]],\n",
    "                                              [[[101, 1020, 1013, 1021, 102],[101, 2603, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1055, 102, 0, 0],\n",
    "                                                 [101, 2484, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1049, 102, 0, 0],\n",
    "                                                 [101, 2423, 102, 0, 0]]],\n",
    "                                              [[[101, 1020, 1013, 1021, 102],[101, 2603, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1055, 102, 0, 0],\n",
    "                                                 [101, 2484, 102, 0, 0]],\n",
    "\n",
    "                                                [[101, 1049, 102, 0, 0],\n",
    "                                                 [101, 2423, 102, 0, 0]]]], device='cuda:0')\n",
    "    , 'mask': tensor([[[[True, True, True, True, True],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]]],\n",
    "                     [[[True, True, True, True, True],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]]],\n",
    "                     [[[True, True, True, True, True],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]],\n",
    "\n",
    "                       [[True, True, True, False, False],\n",
    "                        [True, True, True, False, False]]]], device='cuda:0')\n",
    "    , 'type_ids': tensor([[[[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]]],\n",
    "                         [[[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]]],\n",
    "                         [[[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]],\n",
    "\n",
    "                           [[0, 0, 0, 0, 0],\n",
    "                            [0, 0, 0, 0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d9a9adc-544e-4439-a7b0-23727f913c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample Input\n",
    "table_info = [{'table_id': 'table-0875-744', 'num_rows': 57, 'num_cols': 2, 'header': ['Edition', 'Year'], 'cell_lables': None, 'col_lables': None, 'table_lables': None, 'table_data_raw': [['1st', '1957'], ['2nd', '1958'], ['3rd', '1959'], ['4th', '1960'], ['5th', '1961'], ['6th', '1962'], ['7th', '1963'], ['8th', '1964'], ['9th', '1965'], ['10th', '1966'], ['11th', '1967'], ['12th', '1968'], ['13th', '1969'], ['14th', '1970'], ['15th', '1971'], ['16th', '1972'], ['17th', '1973'], ['18th', '1974'], ['19th', '1975'], ['20th', '1976'], ['21st', '1977'], ['22nd', '1978'], ['23rd', '1979'], ['24th', '1980'], ['25th', '1981'], ['26th', '1982'], ['27th', '1983'], ['28th', '1984'], ['29th', '1985'], ['30th', '1986'], ['31st', '1987'], ['32nd', '1988'], ['33rd', '1989'], ['34th', '1990'], ['35th', '1991'], ['36th', '1992'], ['37th', '1993'], ['38th', '1994'], ['39th', '1995'], ['40th', '1996'], ['41st', '1997'], ['42nd', '1998'], ['43rd', '1999'], ['44th', '2000'], ['45th', '2001'], ['46th', '2002'], ['47th', '2003'], ['48th', '2004'], ['49th', '2005'], ['50th', '2006'], ['—', '2007'], ['51st', '2008'], ['52nd', '2009'], ['53rd', '2010'], ['54th', '2011'], ['55th', '2012'], ['56th', '2013']], 'table': [['Edition', 'Year'], ['1st', '1957'], ['2nd', '1958'], ['3rd', '1959'], ['4th', '1960'], ['5th', '1961'], ['6th', '1962'], ['7th', '1963'], ['8th', '1964'], ['9th', '1965'], ['10th', '1966'], ['11th', '1967'], ['12th', '1968'], ['13th', '1969'], ['14th', '1970'], ['15th', '1971'], ['16th', '1972'], ['17th', '1973'], ['18th', '1974'], ['19th', '1975'], ['20th', '1976'], ['21st', '1977'], ['22nd', '1978'], ['23rd', '1979'], ['24th', '1980'], ['25th', '1981'], ['26th', '1982'], ['27th', '1983'], ['28th', '1984'], ['29th', '1985'], ['30th', '1986'], ['31st', '1987'], ['32nd', '1988'], ['33rd', '1989'], ['34th', '1990'], ['35th', '1991'], ['36th', '1992'], ['37th', '1993'], ['38th', '1994'], ['39th', '1995'], ['40th', '1996'], ['41st', '1997'], ['42nd', '1998'], ['43rd', '1999'], ['44th', '2000'], ['45th', '2001'], ['46th', '2002'], ['47th', '2003'], ['48th', '2004'], ['49th', '2005'], ['50th', '2006'], ['—', '2007'], ['51st', '2008'], ['52nd', '2009'], ['53rd', '2010'], ['54th', '2011'], ['55th', '2012'], ['56th', '2013']]}]\n",
    "\n",
    "indexed_headers = {'bert': {'token_ids': tensor([[[3179],\n",
    "         [2095]]], device='cuda:0'), 'mask': tensor([[[True],\n",
    "         [True]]], device='cuda:0'), 'type_ids': tensor([[[0],\n",
    "         [0]]], device='cuda:0')}}\n",
    "\n",
    "indexed_cells = {'bert': {'token_ids': tensor([[[[ 3083,     0],\n",
    "          [ 3890,     0]],\n",
    "\n",
    "         [[ 3416,     0],\n",
    "          [ 3845,     0]],\n",
    "\n",
    "         [[ 3822,     0],\n",
    "          [ 3851,     0]],\n",
    "\n",
    "         [[ 4343,     0],\n",
    "          [ 3624,     0]],\n",
    "\n",
    "         [[ 4833,     0],\n",
    "          [ 3777,     0]],\n",
    "\n",
    "         [[ 5351,     0],\n",
    "          [ 3705,     0]],\n",
    "\n",
    "         [[ 5504,     0],\n",
    "          [ 3699,     0]],\n",
    "\n",
    "         [[ 5893,     0],\n",
    "          [ 3546,     0]],\n",
    "\n",
    "         [[ 6280,     0],\n",
    "          [ 3551,     0]],\n",
    "\n",
    "         [[ 6049,     0],\n",
    "          [ 3547,     0]],\n",
    "\n",
    "         [[ 6252,     0],\n",
    "          [ 3476,     0]],\n",
    "\n",
    "         [[ 5940,     0],\n",
    "          [ 3380,     0]],\n",
    "\n",
    "         [[ 6122,     0],\n",
    "          [ 3440,     0]],\n",
    "\n",
    "         [[ 6400,     0],\n",
    "          [ 3359,     0]],\n",
    "\n",
    "         [[ 6286,     0],\n",
    "          [ 3411,     0]],\n",
    "\n",
    "         [[ 5767,     0],\n",
    "          [ 3285,     0]],\n",
    "\n",
    "         [[ 5550,     0],\n",
    "          [ 3381,     0]],\n",
    "\n",
    "         [[ 4985,     0],\n",
    "          [ 3326,     0]],\n",
    "\n",
    "         [[ 3708,     0],\n",
    "          [ 3339,     0]],\n",
    "\n",
    "         [[ 3983,     0],\n",
    "          [ 3299,     0]],\n",
    "\n",
    "         [[ 7398,     0],\n",
    "          [ 3355,     0]],\n",
    "\n",
    "         [[13816,     0],\n",
    "          [ 3301,     0]],\n",
    "\n",
    "         [[13928,     0],\n",
    "          [ 3245,     0]],\n",
    "\n",
    "         [[13386,     0],\n",
    "          [ 3150,     0]],\n",
    "\n",
    "         [[10965,     0],\n",
    "          [ 3261,     0]],\n",
    "\n",
    "         [[14935,     0],\n",
    "          [ 3196,     0]],\n",
    "\n",
    "         [[15045,     0],\n",
    "          [ 3172,     0]],\n",
    "\n",
    "         [[15538,     0],\n",
    "          [ 3118,     0]],\n",
    "\n",
    "         [[16318,     0],\n",
    "          [ 3106,     0]],\n",
    "\n",
    "         [[13293,     0],\n",
    "          [ 3069,     0]],\n",
    "\n",
    "         [[17089,     0],\n",
    "          [ 3055,     0]],\n",
    "\n",
    "         [[20628,     0],\n",
    "          [ 2997,     0]],\n",
    "\n",
    "         [[20883,     0],\n",
    "          [ 2960,     0]],\n",
    "\n",
    "         [[20460,     0],\n",
    "          [ 2901,     0]],\n",
    "\n",
    "         [[20198,     0],\n",
    "          [ 2889,     0]],\n",
    "\n",
    "         [[21460,     0],\n",
    "          [ 2826,     0]],\n",
    "\n",
    "         [[23027,     0],\n",
    "          [ 2857,     0]],\n",
    "\n",
    "         [[22051,     0],\n",
    "          [ 2807,     0]],\n",
    "\n",
    "         [[22702,     0],\n",
    "          [ 2786,     0]],\n",
    "\n",
    "         [[16541,     0],\n",
    "          [ 2727,     0]],\n",
    "\n",
    "         [[24233,     0],\n",
    "          [ 2722,     0]],\n",
    "\n",
    "         [[21373,     0],\n",
    "          [ 2687,     0]],\n",
    "\n",
    "         [[25747,     0],\n",
    "          [ 2639,     0]],\n",
    "\n",
    "         [[26409,     0],\n",
    "          [ 2456,     0]],\n",
    "\n",
    "         [[24634,     0],\n",
    "          [ 2541,     0]],\n",
    "\n",
    "         [[27990,     0],\n",
    "          [ 2526,     0]],\n",
    "\n",
    "         [[28243,     0],\n",
    "          [ 2494,     0]],\n",
    "\n",
    "         [[27787,     0],\n",
    "          [ 2432,     0]],\n",
    "\n",
    "         [[25726,     0],\n",
    "          [ 2384,     0]],\n",
    "\n",
    "         [[12951,     0],\n",
    "          [ 2294,     0]],\n",
    "\n",
    "         [[ 1517,     0],\n",
    "          [ 2289,     0]],\n",
    "\n",
    "         [[26017,     0],\n",
    "          [ 2263,     0]],\n",
    "\n",
    "         [[26898,     0],\n",
    "          [ 2268,     0]],\n",
    "\n",
    "         [[ 5187,  4103],\n",
    "          [ 2230,     0]],\n",
    "\n",
    "         [[29570,     0],\n",
    "          [ 2249,     0]],\n",
    "\n",
    "         [[29075,     0],\n",
    "          [ 2262,     0]],\n",
    "\n",
    "         [[29087,     0],\n",
    "          [ 2286,     0]]]], device='cuda:0'), 'mask': tensor([[[[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True,  True],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]],\n",
    "\n",
    "         [[ True, False],\n",
    "          [ True, False]]]], device='cuda:0'), 'type_ids': tensor([[[[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]],\n",
    "\n",
    "         [[0, 0],\n",
    "          [0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "110e8394-474f-400d-a60f-63a385df594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing TableembedderTorch module\n",
    "from table_embedder.models.finetune_entitables_cp import TableEmbedder, TableEmbedderHypers\n",
    "hypers = TableEmbedderHypers()\n",
    "model = TableEmbedder(hypers).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c410ff8-ac51-4fd5-9dca-bc92d270cf38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m(142)\u001b[0;36mget_tabemb\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    140 \u001b[0;31m            \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    141 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 142 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    143 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m(143)\u001b[0;36mget_tabemb\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    141 \u001b[0;31m                \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    142 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 143 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    144 \u001b[0;31m                \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    145 \u001b[0;31m                \u001b[0;31m# table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  row_pos_ids.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  row_pos_embs.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 768])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  n_rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.hypers.num_max_row_pos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit()\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/scratch/gypsum-gpu140/3016139/ipykernel_878133/1191245428.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindexed_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed_cells\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, table_info, indexed_headers, indexed_cells, labels)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         row_embs, col_embs, n_rows_cls, n_cols_cls = self.get_tabemb(bert_header, bert_cell, n_rows, n_cols, bs,\n\u001b[0;32m--> 222\u001b[0;31m                                                                      table_mask, nrows, ncols)\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;31m# To fine-tune TABBIE on this task, we first concatenate the column [CLSCOL]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m in \u001b[0;36mget_tabemb\u001b[0;34m(self, bert_header, bert_data, n_rows, n_cols, bs, table_mask, nrows, ncols)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;31m# table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/tabbie_dev/table_embedder/models/finetune_entitables_cp.py\u001b[0m in \u001b[0;36mget_tabemb\u001b[0;34m(self, bert_header, bert_data, n_rows, n_cols, bs, table_mask, nrows, ncols)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableUtil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_cls_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrow_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m                 \u001b[0mbert_data\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcol_pos_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rows\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0;31m# table_mask = TableUtil.add_cls_mask(table_mask, table_info, bs, n_rows, n_cols, self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/arnaik_umass_edu/.conda/envs/table_emb_py37/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss, prob = model(table_info,indexed_headers, indexed_cells, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18754aee-6e77-4684-a63f-f05960fd4a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc74d72-5394-40a1-abc6-966c421f6244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db50bb4-56c2-431f-b2b2-0e6c2dda5fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34af98d-13f6-43a9-9f71-b21e146c4038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6047c7-a06b-4e2e-bdd5-c2af4263f47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f0c777-8731-4629-b109-a5535d8f8ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634678e8-2faa-4e52-b940-4577720e9290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e49178-68b5-4363-9e18-5092f228578c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469d21a7-37c9-46ce-b6d0-e048183bd394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the torch Model\n",
    "import torch\n",
    "model_namedparam = torch.load('/work/arnaik_umass_edu/model_named.pt')\n",
    "model_param = torch.load('/work/arnaik_umass_edu/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8734c73-4a98-414d-a08e-de09c0d9334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7e2afa0-c16c-42af-a180-26d9042daf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_namedparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "437eebe3-0923-4707-9f77-7f6b2e56fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7af9c502-ff38-477e-b6ee-6a32862f1a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.load('/work/arnaik_umass_edu/tabbie/data/clsrow.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "761e9c2e-b51a-4bdc-be63-0c3b54104e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89da88b-4e20-49f8-ad2f-ebfa22946745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c03870d-daaa-4224-b8f6-be0117e8fe47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa0db6-ff9b-4dee-ba29-a8d7b4457284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce761a-ea4b-467b-b033-d80e115254b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134989f5-65cb-40a3-9b05-5b5507fa41f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b190310-13fd-4cca-9b98-e01b612ed196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c060a-d810-4ebd-9adc-10981f39d003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63357b-465a-4b37-bd43-6bd3be2ce36d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5d9012-0674-4fe4-84fc-d5b4aa9f30ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_info = [{'table_id': '1438042981460.12__CC-MAIN-20150728002301-00003-ip-10-236-191-2.ec2.internal__1387'\n",
    "               , 'num_rows': 4\n",
    "               , 'num_cols': 7\n",
    "               , 'header': ['size', 'us', 'type', 'china', 'gaa', 'eu', 'years']\n",
    "               , 'cell_labels': None\n",
    "               , 'col_labels': [2, 4, 6]\n",
    "               , 'table_labels': None\n",
    "               , 'table_data_raw': [['xs', '6/7', '9.125', '235', '23', '36-37', '4']\n",
    "                                    , ['s', '7/8', '9.5', '245', '24', '38-39', '5']\n",
    "                                    , ['m', '8/9', '9.875', '255', '25', '39-40', '6']\n",
    "                                    , ['l', '9/10', '10.375', '265', '26', '40-41', '7']]\n",
    "               , 'table': [['size', 'us', 'type', 'china', 'gaa', 'eu', 'years']\n",
    "                           , ['xs', '6/7', '9.125', '235', '23', '36-37', '4']\n",
    "                           , ['s', '7/8', '9.5', '245', '24', '38-39', '5']\n",
    "                           , ['m', '8/9', '9.875', '255', '25', '39-40', '6']\n",
    "                           , ['l', '9/10', '10.375', '265', '26', '40-41', '7']]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d82c3529-e4cb-4eac-a448-ed3eb6472027",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_headers = {'bert': {'token_ids': tensor([[[  101,  2946,   102],\n",
    "         [  101,  2149,   102],\n",
    "         [  101,  2828,   102],\n",
    "         [  101,  2859,   102],\n",
    "         [  101, 19930,   102],\n",
    "         [  101,  7327,   102],\n",
    "         [  101,  2086,   102]]], device='cuda:0')\n",
    ", 'mask': tensor([[[True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True],\n",
    "         [True, True, True]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03d92c34-a4f0-43ab-b3c2-d8130626a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_cells = {'bert': {'token_ids': tensor([[[[  101,  1060,  2015,   102,     0],\n",
    "          [  101,  1020,  1013,  1021,   102],\n",
    "          [  101,  1023,  1012,  8732,   102],\n",
    "          [  101, 17825,   102,     0,     0],\n",
    "          [  101,  2603,   102,     0,     0],\n",
    "          [  101,  4029,  1011,  4261,   102],\n",
    "          [  101,  1018,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1055,   102,     0,     0],\n",
    "          [  101,  1021,  1013,  1022,   102],\n",
    "          [  101,  1023,  1012,  1019,   102],\n",
    "          [  101, 21005,   102,     0,     0],\n",
    "          [  101,  2484,   102,     0,     0],\n",
    "          [  101,  4229,  1011,  4464,   102],\n",
    "          [  101,  1019,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1049,   102,     0,     0],\n",
    "          [  101,  1022,  1013,  1023,   102],\n",
    "          [  101,  1023,  1012, 27658,   102],\n",
    "          [  101, 20637,   102,     0,     0],\n",
    "          [  101,  2423,   102,     0,     0],\n",
    "          [  101,  4464,  1011,  2871,   102],\n",
    "          [  101,  1020,   102,     0,     0]],\n",
    "\n",
    "         [[  101,  1048,   102,     0,     0],\n",
    "          [  101,  1023,  1013,  2184,   102],\n",
    "          [  101,  2184,  1012, 18034,   102],\n",
    "          [  101, 20549,   102,     0,     0],\n",
    "          [  101,  2656,   102,     0,     0],\n",
    "          [  101,  2871,  1011,  4601,   102],\n",
    "          [  101,  1021,   102,     0,     0]]]], device='cuda:0')\n",
    ", 'mask': tensor([[[[ True,  True,  True,  True, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]],\n",
    "\n",
    "         [[ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True, False, False],\n",
    "          [ True,  True,  True,  True,  True],\n",
    "          [ True,  True,  True, False, False]]]], device='cuda:0')\n",
    ", 'type_ids': tensor([[[[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]],\n",
    "\n",
    "         [[0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0],\n",
    "          [0, 0, 0, 0, 0]]]], device='cuda:0')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43d746-265f-4f1f-93a4-8409a15156cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39376381-4b6f-4767-b667-68c3a74d4350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb6dc9-46ea-4b1e-b91c-8bb8418e1c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c81d12-512f-4130-8c17-8a5cd81d6753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f000a1-ef55-46f5-b694-7faaf5c0de06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aedbf86-e619-4f09-9363-a1d61db4b7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d9dab-70f9-4635-b7d7-e3d2501c345a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5547fea9-2278-417a-b52a-3461dce527b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58bcf90-a702-4564-aaf6-f1b1842a99dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce9e603-43b5-493f-ad3d-23e3241e1aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568a1e9-9376-43f8-ba92-9e885ae33e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4878f4b9-ef14-4875-b4cd-341186dc15c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee20e0-de16-454f-98b6-4946fb92055c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684b50e-a512-4313-a775-f919d7b378ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e37ab16-73c2-47fa-ac6c-136328712e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99ad85-c66d-4a02-8aa2-29f876859401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125ad12-c839-48ff-870f-0beec67896be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78073863-f787-4dc0-86b5-53f9301d0689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce72e4-2f44-4ce7-884f-fbc03fca4e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd638709-f91c-4222-a621-800f1db75292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44678242-ab7e-41d9-bc64-a83242cf045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1dd9a-970d-43c6-8ae1-4e08b3570165",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c18204-64e5-4b6d-b953-814ae6aa08f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b70c6-2221-4568-9b84-9af8307dcd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-vinyl",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-table_emb_py37)",
   "language": "python",
   "name": "conda-env-.conda-table_emb_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
